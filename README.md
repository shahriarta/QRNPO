# Quasi Riemannian Newton Policy Optimization (QRNPO)



In this repository, we provide the code for the simulations of the following manuscript:  <br> <br>


### [Policy Optimization over Submanifolds for Linearly Constrained Feedback Synthesis](https://arxiv.org/pdf/2201.11157)

Shahriar Talebi, Mehran Mesbahi <br> <br>


---

## Abstract

<div align="justify"> In this project, we study linearly constrained policy optimization over the manifold of Schur stabilizing controllers, equipped with a Riemannian metric that emerges naturally in the context of optimal control problems. We provide extrinsic analysis of a generic constrained smooth cost function, that subsequently facilitates subsuming any such constrained problem into this framework. By studying the second order geometry of this manifold, we provide a Newton-type algorithm that does not rely on the exponential mapping nor a retraction, while ensuring local convergence guarantees. The algorithm hinges instead upon the developed stability certificate and the linear structure of the constraints. We then apply our methodology to two well-known constrained optimal control problems. Finally, several numerical examples showcase the performance of the proposed algorithm. </div> <br>

![Submanifold of stabilizing controllers](https://github.com/shahriarta/QRNPO/blob/main/motivation.png)


